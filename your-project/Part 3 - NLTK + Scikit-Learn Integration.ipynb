{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK + Scikit-Learn Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the 5k processed comments sample DF\n",
    "df = pd.read_csv('Datasets/comments_5ksample.csv')\n",
    "\n",
    "# Dropping the unnamed column\n",
    "df.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing opening the pickled naive bayes\n",
    "classifier_f = open('naivebayes.pickle', 'rb')\n",
    "classifier_og = pickle.load(classifier_f)\n",
    "classifier_f.close()\n",
    "\n",
    "classifier_og  # this one is the trained algo with the whole comments df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions that shouldn't be needed since I already had the cleaned dataframe from the previous notebook...\n",
    "## still, had to get all of this again and now the outputs are working as expected...\n",
    "\n",
    "# Defining functions to cleanup and process the comments\n",
    "def clean_up(s):\n",
    "    return re.sub(r'  *', ' ', re.sub(r'[^a-z]', ' ', \n",
    "                                      re.sub(r'www\\.\\S*', ' ', re.sub(r'http[s]?://\\S*', ' ', s.lower())))).strip()\n",
    "\n",
    "def tokenize(s):\n",
    "    return nltk.word_tokenize(s)\n",
    "\n",
    "def stem_and_lemmatize(l):\n",
    "    ps = PorterStemmer()\n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    stemmed_list = [ps.stem(w) for w in l]\n",
    "    lemmed_on_stemmed_list = [wnl.lemmatize(w) for w in stemmed_list]\n",
    "    \n",
    "    return lemmed_on_stemmed_list\n",
    "\n",
    "def remove_stopwords(lst, lang = 'english'):\n",
    "    stop_words = stopwords.words(lang)\n",
    "    return [word for word in lst if word not in stop_words]\n",
    "\n",
    "\n",
    "# actually needed functions\n",
    "# Building the features\n",
    "def find_features(document, bow):\n",
    "    text = document.lower()\n",
    "    features = dict()\n",
    "    for w, c in bow:\n",
    "        features[w] = w in text\n",
    "    return features\n",
    "\n",
    "def make_matrix(series_text, series_target, bow):\n",
    "    return [(find_features(s, bow), t) for s, t in zip(series_text.values, series_target.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Userscore</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Username</th>\n",
       "      <th>Comments_Processed</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pro Evolution Soccer 2015</td>\n",
       "      <td>PlayStation4</td>\n",
       "      <td>10</td>\n",
       "      <td>this game is absolutely awesome. i am happy th...</td>\n",
       "      <td>call_of_duty</td>\n",
       "      <td>[thi, game, absolut, awesom, happi, took, one,...</td>\n",
       "      <td>Pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Battlefield: Bad Company 2</td>\n",
       "      <td>PC</td>\n",
       "      <td>10</td>\n",
       "      <td>The guy who said his PC can't run the game, I...</td>\n",
       "      <td>LentiniM</td>\n",
       "      <td>[guy, said, hi, pc, run, game, guess, singl, c...</td>\n",
       "      <td>Pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sly Cooper and the Thievius Raccoonus</td>\n",
       "      <td>PlayStation2</td>\n",
       "      <td>8</td>\n",
       "      <td>A solid game however it does get repetitive ov...</td>\n",
       "      <td>AKthaBeast</td>\n",
       "      <td>[solid, game, howev, doe, get, repetit, awhil,...</td>\n",
       "      <td>Pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Call of Duty: Black Ops II</td>\n",
       "      <td>Xbox360</td>\n",
       "      <td>4</td>\n",
       "      <td>I was excited to pick this game up after readi...</td>\n",
       "      <td>ctruluck1324</td>\n",
       "      <td>[wa, excit, pick, thi, game, read, review, cri...</td>\n",
       "      <td>Neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Middle-earth: Shadow of Mordor</td>\n",
       "      <td>PlayStation4</td>\n",
       "      <td>10</td>\n",
       "      <td>This is by far the most fun I have had dismemb...</td>\n",
       "      <td>shadowmancer66</td>\n",
       "      <td>[thi, far, fun, dismemb, orc, long, time, shad...</td>\n",
       "      <td>Pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>The Legend of Zelda: A Link Between Worlds</td>\n",
       "      <td>3DS</td>\n",
       "      <td>10</td>\n",
       "      <td>A great follow up to 'A Link To The Past'. The...</td>\n",
       "      <td>ForeverFalling</td>\n",
       "      <td>[great, follow, link, past, soundtrack, one, b...</td>\n",
       "      <td>Pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>The Witcher 2: Assassins of Kings</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>Alright let me begin by saying that this game ...</td>\n",
       "      <td>akelz7</td>\n",
       "      <td>[alright, let, begin, say, thi, game, goti, ma...</td>\n",
       "      <td>Pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Fallout 4</td>\n",
       "      <td>PlayStation4</td>\n",
       "      <td>10</td>\n",
       "      <td>This review contains spoilers, cli...</td>\n",
       "      <td>Ninja-Puffs</td>\n",
       "      <td>[thi, review, contain, spoiler, click, expand,...</td>\n",
       "      <td>Pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>NBA 2K18</td>\n",
       "      <td>PlayStation4</td>\n",
       "      <td>0</td>\n",
       "      <td>MyTeam is a joke. MyGm is the worst manager mo...</td>\n",
       "      <td>zizhazhu</td>\n",
       "      <td>[myteam, joke, mygm, worst, manag, mode, exper...</td>\n",
       "      <td>Neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>The Sims 2</td>\n",
       "      <td>PC</td>\n",
       "      <td>10</td>\n",
       "      <td>Good.</td>\n",
       "      <td>BrianT.</td>\n",
       "      <td>[good]</td>\n",
       "      <td>Pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Title      Platform  Userscore  \\\n",
       "0                      Pro Evolution Soccer 2015  PlayStation4         10   \n",
       "1                     Battlefield: Bad Company 2            PC         10   \n",
       "2          Sly Cooper and the Thievius Raccoonus  PlayStation2          8   \n",
       "3                     Call of Duty: Black Ops II       Xbox360          4   \n",
       "4                 Middle-earth: Shadow of Mordor  PlayStation4         10   \n",
       "...                                          ...           ...        ...   \n",
       "4995  The Legend of Zelda: A Link Between Worlds           3DS         10   \n",
       "4996           The Witcher 2: Assassins of Kings            PC          5   \n",
       "4997                                   Fallout 4  PlayStation4         10   \n",
       "4998                                    NBA 2K18  PlayStation4          0   \n",
       "4999                                  The Sims 2            PC         10   \n",
       "\n",
       "                                                Comment        Username  \\\n",
       "0     this game is absolutely awesome. i am happy th...    call_of_duty   \n",
       "1      The guy who said his PC can't run the game, I...        LentiniM   \n",
       "2     A solid game however it does get repetitive ov...      AKthaBeast   \n",
       "3     I was excited to pick this game up after readi...    ctruluck1324   \n",
       "4     This is by far the most fun I have had dismemb...  shadowmancer66   \n",
       "...                                                 ...             ...   \n",
       "4995  A great follow up to 'A Link To The Past'. The...  ForeverFalling   \n",
       "4996  Alright let me begin by saying that this game ...          akelz7   \n",
       "4997              This review contains spoilers, cli...     Ninja-Puffs   \n",
       "4998  MyTeam is a joke. MyGm is the worst manager mo...        zizhazhu   \n",
       "4999                                              Good.         BrianT.   \n",
       "\n",
       "                                     Comments_Processed Target  \n",
       "0     [thi, game, absolut, awesom, happi, took, one,...    Pos  \n",
       "1     [guy, said, hi, pc, run, game, guess, singl, c...    Pos  \n",
       "2     [solid, game, howev, doe, get, repetit, awhil,...    Pos  \n",
       "3     [wa, excit, pick, thi, game, read, review, cri...    Neg  \n",
       "4     [thi, far, fun, dismemb, orc, long, time, shad...    Pos  \n",
       "...                                                 ...    ...  \n",
       "4995  [great, follow, link, past, soundtrack, one, b...    Pos  \n",
       "4996  [alright, let, begin, say, thi, game, goti, ma...    Pos  \n",
       "4997  [thi, review, contain, spoiler, click, expand,...    Pos  \n",
       "4998  [myteam, joke, mygm, worst, manag, mode, exper...    Neg  \n",
       "4999                                             [good]    Pos  \n",
       "\n",
       "[5000 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doing this again, even though it shouldn't be necessary, but since it wasn't working...\n",
    "df['Comments_Processed'] = df['Comment'].apply(lambda x: remove_stopwords(stem_and_lemmatize(tokenize(clean_up(x)))))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the Original NLTK NB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   grace = True              Neg : Pos    =     13.6 : 1.0\n",
      "               fundament = True              Neg : Pos    =     13.6 : 1.0\n",
      "                 acclaim = True              Neg : Pos    =     13.6 : 1.0\n",
      "                    peer = True              Neg : Pos    =     13.6 : 1.0\n",
      "                    reus = True              Neg : Pos    =     13.6 : 1.0\n",
      "                   messi = True              Neg : Pos    =     13.6 : 1.0\n",
      "                    scam = True              Neg : Pos    =     13.6 : 1.0\n",
      "                   queue = True              Neg : Pos    =     11.8 : 1.0\n",
      "                  ticket = True              Neg : Pos    =     11.0 : 1.0\n",
      "                 desktop = True              Neg : Pos    =     10.6 : 1.0\n",
      "                  tester = True              Neg : Pos    =     10.6 : 1.0\n",
      "                 fastest = True              Neg : Pos    =     10.6 : 1.0\n",
      "                   drain = True              Neg : Pos    =     10.6 : 1.0\n",
      "                   fleet = True              Neg : Pos    =     10.6 : 1.0\n",
      "                  mundan = True              Neg : Pos    =     10.6 : 1.0\n",
      "\n",
      " Original NLTK NB accuracy: 84.48%\n"
     ]
    }
   ],
   "source": [
    "# INITIALIZING EVERYTHING TO BEGIN TESTING WITH DIFFERENT MODELS\n",
    "\n",
    "# Creating the bag of words\n",
    "bow = [word for lst in df['Comments_Processed'] for word in lst]\n",
    "fdist = FreqDist(bow)\n",
    "\n",
    "# Getting just the 5k most common words\n",
    "most_common = fdist.most_common(5000)\n",
    "\n",
    "# Building the features and making the matrix\n",
    "matrix = make_matrix(df['Comment'], df['Target'], most_common)\n",
    "\n",
    "# Defining the size to use for the training and testing\n",
    "size = int(len(matrix) * 0.25)  # xxx -> 25% of the data\n",
    "\n",
    "# Training with 75% of the data and testing against the remaining 25%\n",
    "training_set = matrix[size:]\n",
    "testing_set = matrix[:size]\n",
    "\n",
    "# Initializing and training the model\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "# Showing the top 15 most informative features\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "# Printing the model's accuracy\n",
    "print('\\n', 'Original NLTK NB accuracy:', str(round(nltk.classify.accuracy(classifier, testing_set) * 100, 2)) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB accuracy: 87.76%\n"
     ]
    }
   ],
   "source": [
    "# Testing the Multinomial NB model\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "#MNB_classifier.show_most_informative_features(15)  # thought this would work, but guess not\n",
    "\n",
    "print('MultinomialNB accuracy:', str(round(nltk.classify.accuracy(MNB_classifier, testing_set) * 100, 2)) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB accuracy: 83.2%\n"
     ]
    }
   ],
   "source": [
    "# Testing the Bernoulli NB model\n",
    "BNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BNB_classifier.train(training_set)\n",
    "\n",
    "print('BernoulliNB accuracy:', str(round(nltk.classify.accuracy(BNB_classifier, testing_set) * 100, 2)) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattymrc/.pyenv/versions/3.7.5/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_classifier accuracy: 87.2%\n"
     ]
    }
   ],
   "source": [
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "\n",
    "print('LogisticRegression_classifier accuracy:', \n",
    "      str(round(nltk.classify.accuracy(LogisticRegression_classifier, testing_set) * 100, 2)) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier_classifier accuracy: 84.4%\n"
     ]
    }
   ],
   "source": [
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "\n",
    "print('SGDClassifier_classifier accuracy:', \n",
    "      str(round(nltk.classify.accuracy(SGDClassifier_classifier, testing_set) * 100, 2)) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC_classifier accuracy: 85.2%\n"
     ]
    }
   ],
   "source": [
    "SVC_classifier = SklearnClassifier(SVC())\n",
    "SVC_classifier.train(training_set)\n",
    "\n",
    "print('SVC_classifier accuracy:', \n",
    "      str(round(nltk.classify.accuracy(SVC_classifier, testing_set) * 100, 2)) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC_classifier accuracy: 85.2%\n"
     ]
    }
   ],
   "source": [
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "\n",
    "print('LinearSVC_classifier accuracy:', \n",
    "      str(round(nltk.classify.accuracy(LinearSVC_classifier, testing_set) * 100, 2)) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one isn't working\n",
    "'''NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(training_set)\n",
    "\n",
    "print('NuSVC_classifier accuracy:', \n",
    "      str(round(nltk.classify.accuracy(NuSVC_classifier, testing_set) * 100, 2)) + '%')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
